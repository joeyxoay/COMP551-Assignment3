# -*- coding: utf-8 -*-
"""551A3- BERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UnnVtu0Qty0_8I_ZykmyqMB1ISpP2cuv

# **Task 1 - Load Data**
"""

!pip install datasets
!pip install accelerate -U

from datasets import load_dataset

!pip install transformers torch
from transformers import BertTokenizer
from transformers import BertForSequenceClassification
from transformers import Trainer, TrainingArguments
import torch

dataset = load_dataset("dair-ai/emotion")

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize(batch):
  return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=65)

dataset_encodings = dataset.map(tokenize, batched=True)

emotion_labels = ['joy', 'anger', 'love', 'sadness', 'fear', 'surprise']
test_labels = [example['label'] for example in dataset_encodings["test"]]
predicted_emotions_test = [emotion_labels[id] for id in test_labels]

validation_labels = [example['label'] for example in dataset_encodings["validation"]]
predicted_emotions_validation = [emotion_labels[id] for id in validation_labels]

train_labels = [example['label'] for example in dataset_encodings["train"]]
predicted_emotions_train = [emotion_labels[id] for id in train_labels]

from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt

def wordCloud(data):
  word_freq = dict(Counter(data))

  wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

  plt.figure(figsize=(10, 8))
  plt.imshow(wordcloud, interpolation='bilinear')

  plt.axis('off')
  i = 0
  for word, freq in word_freq.items():
      plt.text(0, i, f"{word}: {freq}", horizontalalignment='left', verticalalignment='bottom')
      i += 20
  plt.show()

wordCloud(predicted_emotions_test)
wordCloud(predicted_emotions_validation)
wordCloud(predicted_emotions_train)

model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)

"""### Training BERT model"""

training_args = TrainingArguments("test_trainer", evaluation_strategy="epoch")
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset_encodings["train"],
    eval_dataset=dataset_encodings["validation"]
)
trainer.train()

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("Using GPU:", torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print("Using CPU")

#Testing with individual sentences
sentence = "This assignment is hard"
inputs = tokenizer(sentence, return_tensors="pt")
inputs = {k: v.to(device) for k, v in inputs.items()}
outputs = model(**inputs)
predictions = torch.argmax(outputs.logits, dim=-1)
print(predictions)

def predict_emotions(test_data, model, device):
    model.eval()
    predictions = []

    with torch.no_grad():
        for item in test_data:
            inputs = tokenizer(item['text'], return_tensors="pt", padding=True, truncation=True, max_length=65)
            inputs = {k: v.to(device) for k, v in inputs.items()}

            outputs = model(**inputs)
            logits = outputs.logits
            predicted_class_id = torch.argmax(logits, dim=-1).item()
            predictions.append(predicted_class_id)

    return predictions

# Perform predictions
test_predictions = predict_emotions(dataset_encodings["test"], model, device)

emotion_labels = ['joy', 'anger', 'love', 'sadness', 'fear', 'surprise']
true_labels = [example['label'] for example in dataset_encodings["test"]]
predicted_emotions = [emotion_labels[id] for id in test_predictions]

print(true_labels)
print(test_predictions)
print(predicted_emotions)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
data = {'True Values': true_labels, 'Predicted Values': test_predictions}
results = pd.DataFrame(data)

confusion_matrix = pd.crosstab(results['True Values'], results['Predicted Values'], rownames=['True'], colnames=['Predicted'])

plt.figure(figsize=(6, 4))
heatmap = sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')

plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

accuracy_percentage = calculate_accuracy(true_labels, test_predictions)
print(f"Model Accuracy: {accuracy_percentage:.2f}%")

def calculate_accuracy(true_labels, predicted_labels):
    correct_predictions = sum([true == pred for true, pred in zip(true_labels, predicted_labels)])
    total_predictions = len(predicted_labels)
    accuracy = correct_predictions / total_predictions
    return accuracy * 100

grid = {
    'num_train_epochs': [2, 3, 4],
    'per_device_train_batch_size': [16, 32],
    'per_device_eval_batch_size': [16, 32],
    'warmup_steps': [0, 500],
    'weight_decay': [0.0, 0.01]
}

# Function to perform grid search
def param_search(model, train_dataset, eval_dataset, test_dataset, num_train_epochs=2, train_batch_size=16, eval_batch_size=16, warmup_steps=0, weight_decay=0, logging_steps=10):
    print("num_train_epochs: ", num_train_epochs)
    print("train_batch_size: ", train_batch_size)
    print("eval_batch_size: ", eval_batch_size)
    print("warmup_steps: ", warmup_steps)
    print("weight_decay: ", weight_decay)
    print("logging_steps: ", logging_steps)
    # Define training arguments
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=num_train_epochs,
        per_device_train_batch_size=train_batch_size,
        per_device_eval_batch_size=eval_batch_size,
        warmup_steps=warmup_steps,
        weight_decay=weight_decay,
        logging_steps=logging_steps,
        evaluation_strategy="epoch"
    )

    # Initialize the Trainer
    trainer_fine_tuning = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset
    )

    # Train the model
    trainer_fine_tuning.train()

    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("Using GPU:", torch.cuda.get_device_name(0))
    else:
        device = torch.device("cpu")
        print("Using CPU")

    #predictions
    test_predictions = predict_emotions(test_dataset, model, device)
    true_labels = [example['label'] for example in test_dataset]
    accuracy_percentage = calculate_accuracy(true_labels, test_predictions)
    print(f"Model Accuracy: {accuracy_percentage:.2f}%")

"""### # of Epoch Comparison"""

param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=2)
param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3)
param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=4)

"""### Train Batch Size and Eval Batch Size Comparison"""

param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3, train_batch_size=16, eval_batch_size=16)
param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3, train_batch_size=32, eval_batch_size=32)

"""### Warmup Steps Comparison"""

param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3, train_batch_size=32, eval_batch_size=32, warmup_steps=0)
param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3, train_batch_size=32, eval_batch_size=32, warmup_steps=500)

"""### Weight Decay Comparison"""

param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3, train_batch_size=32, eval_batch_size=32, warmup_steps=0, weight_decay=0.0)
param_search(model, dataset_encodings["train"], dataset_encodings["validation"], dataset_encodings["test"], num_train_epochs=3, train_batch_size=32, eval_batch_size=32, warmup_steps=0, weight_decay=0.01)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    warmup_steps=0,
    weight_decay=0.0,
    logging_steps=10,
    evaluation_strategy="epoch"
)

# Initialize the Trainer
trainer_fine_tuning = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset_encodings["train"],
    eval_dataset=dataset_encodings["validation"]
)

# Train the model
trainer_fine_tuning.train()

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("Using GPU:", torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print("Using CPU")

#predictions
test_predictions = predict_emotions(dataset_encodings["test"], model, device)

data = {'True Values': true_labels, 'Predicted Values': test_predictions}
results = pd.DataFrame(data)

confusion_matrix = pd.crosstab(results['True Values'], results['Predicted Values'], rownames=['True'], colnames=['Predicted'])

plt.figure(figsize=(6, 4))
heatmap = sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')

plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()